#!/usr/bin/env bash

WAIT_START=60
RSTUDIO_HOME=$1
HADOOP_HOME=$2
HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
PROJECT_USER_NAME=$3
PORT=$4
SECRET_DIR=$5
CERTS_DIR=$6
IMAGE=${7}
LOGFILE=${RSTUDIO_HOME}/logs/$8
PROJECT_NAME=$9
NAMENODE_HOST=${10}
NAMENODE_PORT=${11}
HADOOP_BASE_DIR=${12}
HADOOP_CLIENT_ENV_OPTS='-D fs.permissions.umask-mode=0002'
CONTAINER_NAME=${PROJECT_USER_NAME}__rstudio
PID_FILE=${RSTUDIO_HOME}/run/rstudio.pid
SPARK_CONF_DIR=<%= node['hadoop_spark']['conf_dir'] %> #/srv/hops/spark/conf
FLINK_CONF_DIR=<%= node['flink']['conf_dir'] %>
NOT_FOUND=127

echo "Image name is ${IMAGE}"
help() {
    echo ""
    echo "usage: $0 RSTUDIO_HOME HADOOP_HOME PROJECT_USER_NAME PORT SECRET_DIR CERTS_DIR IMAGE LOGFILE PROJECT_NAME NAMENODE_HOST NAMENODE_PORT HADOOP_BASE_DIR HADOOP_CLIENT_ENV_OPTS"
    echo ""
    exit 1
}

function kill_named {
    CID=$(docker container list -a | grep $CONTAINER_NAME | grep -v grep | awk '{print $1}')
    if [ "$CID" != "" ] ; then
        docker rm -f "$CID" > /dev/null 2>&1
        res=$?
    else
        res=$NOT_FOUND
    fi
    return "$res"
}

if [ $# -ne 12 ]; then
  help
fi

#check if the folders exist
cd "$RSTUDIO_HOME" || exit
cd "$SECRET_DIR" || exit

kill_named

if [ -f "$PID_FILE" ] ; then
    rm $PID_FILE
fi

echo "Secret dir is ${SECRET_DIR}"
docker run --rm -d --privileged --name $CONTAINER_NAME --cidfile=$PID_FILE\
       --network=host \
       --init \
       -e "RSTUDIO_PATH=$RSTUDIO_HOME" \
       -e "RSTUDIO_DATA_DIR=$RSTUDIO_HOME" \
       -e "PDIR=$SECRET_DIR" \
       -e "RSTUDIO_CONFIG_DIR=${RSTUDIO_HOME}/conf" \
       -e "RSTUDIO_RUNTIME_DIR=${RSTUDIO_HOME}/run" \
       -e "HADOOP_HDFS_HOME=${HADOOP_HOME}" \
       -e "HADOOP_CONF_DIR=${HADOOP_CONF_DIR}" \
       -e "HADOOP_CLIENT_OPTS='-Dfs.permissions.umask-mode=0002'" \
       -e "MATERIAL_DIRECTORY=$CERTS_DIR" \
       -e "HADOOP_USER_NAME=$PROJECT_USER_NAME" \
       -e "HADOOP_USER_NAME=$PROJECT_USER_NAME" \
       -e "HADOOP_HOME=${HADOOP_HOME}" \
       -e "LOGFILE=${LOGFILE}" \
       -e "RSTUDIO_PORT=${PORT}" \
       -e "PROJECT_NAME=${PROJECT_NAME}" \
       -e "NAMENODE_HOST=${NAMENODE_HOST}" \
       -e "NAMENODE_PORT=${NAMENODE_PORT}" \
       -e "HADOOP_BASE_DIR=${HADOOP_BASE_DIR}" \
       -e "HADOOP_CLIENT_ENV_OPTS=${HADOOP_CLIENT_ENV_OPTS}" \
       -v $RSTUDIO_HOME:$RSTUDIO_HOME:rw\
       -v $SECRET_DIR:$SECRET_DIR:rw\
       -v ${HADOOP_CONF_DIR}:${HADOOP_CONF_DIR}:ro \
       -v ${SPARK_CONF_DIR}:${SPARK_CONF_DIR}:ro \
       -u="yarnapp" \
       -w="$SECRET_DIR" \
       $IMAGE & \


# Wait for rstudio to start
timeout=0
while [ $timeout -lt $WAIT_START ] ; do
  sleep 1
  grep 'Connecting to sqlite3 database' "$LOGFILE"
        if [ $? -eq 0 ] ; then
          break
        fi
  echo -n "."
  timeout=$((timeout + 1))
done
echo ""

# If the timeout was exceeded, kill JupyterLab
if [ "$timeout" -eq $WAIT_START ] ; then
 kill_named
fi


exit $?